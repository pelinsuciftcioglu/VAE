{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/pelinsuciftcioglu/VAE/blob/main/VAE.ipynb",
      "authorship_tag": "ABX9TyP1Ydy++fKfEEbmelFYtTjz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pelinsuciftcioglu/VAE/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGnGq9I4RJZi"
      },
      "source": [
        "# **Variational Auto-Encoder (VAE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II9CkyMLhgIj"
      },
      "source": [
        "VAE implementation inspired by:\n",
        "- [Tomczak, J. M. (2021). Introduction to Deep Generative Modeling.](https://https://github.com/jmtomczak/intro_dgm)\n",
        "- [CreativeAI: Deep Learning for Graphics Tutorial Code\n",
        "](https://github.com/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr7xJ0hJwUZ5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "use_gpu = True"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7rMFdHqXJYZ"
      },
      "source": [
        "PI = torch.from_numpy(np.asarray(np.pi))\n",
        "EPS = 1.e-5\n",
        "\n",
        "# DISTRBUTION FOR THE DATA (INPUT)\n",
        "\n",
        "def log_categorical(x, x_new, num_classes, reduction=None, dim=None):\n",
        "    x_one_hot = F.one_hot(x.long(), num_classes)\n",
        "    log_p = x_one_hot * torch.log(torch.clamp(x_new, EPS, 1. - EPS))\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "def log_bernoulli(x, x_new, reduction=None, dim=None):\n",
        "    x_new = torch.clamp(x_new, EPS, 1. - EPS)\n",
        "    log_p = x * torch.log(x_new) + (1. - x) * torch.log(1. - x_new)\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "# DISTRIBUTION FOR THE VARIATIONAL INFERENCE\n",
        "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
        "    D = x.shape[1]\n",
        "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2.\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "\n",
        "# PRIOR DISTRIBUTIONS for p(z)\n",
        "\n",
        "def log_standard_normal(x, reduction=None, dim=None):\n",
        "    D = x.shape[1]\n",
        "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * x**2.\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMVbn06LxAM4"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, D, H, L):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.encoder_net = nn.Sequential(nn.Linear(D, H), nn.LeakyReLU(), nn.Linear(H, 2*L))\n",
        "\n",
        "    def encode(self, x):\n",
        "      mu, log_var = self.forward(x)\n",
        "      return mu, log_var\n",
        "\n",
        "    def forward(self, x):\n",
        "      h = self.encoder_net(x)\n",
        "      mu, log_var =  torch.chunk(h, 2, dim=1)\n",
        "\n",
        "      return mu, log_var\n",
        "\n",
        "    def sample(self, mu, log_var):\n",
        "      std = torch.exp(0.5 * log_var)\n",
        "      # Sample epsilon ~ N(0,I)\n",
        "      eps = torch.randn_like(std)\n",
        "      # Reparameterization trick\n",
        "      z = mu + eps * std\n",
        "\n",
        "      return z\n",
        "\n",
        "    def log_prob(self, mu, log_var, z):\n",
        "      return log_normal_diag(z, mu, log_var)\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT7wpoop1PJJ"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, D, H, L, distribution, num_vals):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.D = D\n",
        "        self.distribution = distribution\n",
        "        self.num_vals = num_vals\n",
        "\n",
        "        self.decoder_net = nn.Sequential(nn.Linear(L, H), nn.LeakyReLU(),\n",
        "                                         nn.Linear(H, D * num_vals))\n",
        "\n",
        "    def decode(self, z):\n",
        "      x_new = self.forward(z)\n",
        "\n",
        "      return x_new\n",
        "\n",
        "    def forward(self, z):\n",
        "      x_new = self.decoder_net(z)\n",
        "      \n",
        "      if self.distribution == 'categorical':\n",
        "        b = x_new.shape[0]\n",
        "        d = self.D\n",
        "        x_new = x_new.reshape(b, d, self.num_vals)\n",
        "        return torch.softmax(x_new, 2)\n",
        "      \n",
        "      elif self.distribution == 'bernoulli':\n",
        "        return torch.sigmoid(x_new)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMV2Vv6rYVOM"
      },
      "source": [
        "class Prior(nn.Module):\n",
        "    def __init__(self, L, prior_distribution):\n",
        "        super(Prior, self).__init__()\n",
        "        self.L = L\n",
        "        self.distribution = prior_distribution\n",
        "\n",
        "    # def sample(self, batch_size):\n",
        "    #     z = torch.randn((batch_size, self.L))\n",
        "    #     return z\n",
        "\n",
        "    def log_prob(self, z):\n",
        "      if (self.distribution == 'standard normal'):\n",
        "        return log_standard_normal(z)\n",
        "\n",
        "      # elif self.distribution == ''\n",
        "        # return log____(z)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzfVgQYtP-Lg"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self, D, H, L, distribution, num_vals, prior_distribution): # Initializations should be added!!!!\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = Encoder(D, H, L)\n",
        "        self.decoder = Decoder(D, H, L, distribution, num_vals)\n",
        "        self.prior = Prior(L, prior_distribution)\n",
        "\n",
        "\n",
        "        self.num_vals = num_vals\n",
        "        self.distribution = distribution\n",
        "  \n",
        "  def forward(self, x, reduction='avg'):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        mu, log_var = self.encoder.encode(x)\n",
        "        z = self.encoder.sample(mu, log_var)\n",
        "\n",
        "        ELBO = self.loss(x, z, mu, log_var, reduction)\n",
        "\n",
        "        return ELBO\n",
        "  \n",
        "  def loss(self, x, z, mu, log_var, reduction='avg'):\n",
        "    # Reconstruction Error\n",
        "    RE = self.log_prob(x, z)\n",
        "\n",
        "    # KL-Divergence\n",
        "    KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu, log_var, z)).sum(-1)\n",
        "\n",
        "    if reduction == 'sum':\n",
        "      return -(RE + KL).sum()\n",
        "    else:\n",
        "      return -(RE + KL).mean()\n",
        "\n",
        "\n",
        "  def log_prob(self, x, z):\n",
        "    x_new = self.decoder.decode(z)\n",
        "\n",
        "    if self.distribution == 'categorical':\n",
        "      log_prob = log_categorical(x, x_new, self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
        "            \n",
        "    elif self.distribution == 'bernoulli':\n",
        "      log_prob = log_bernoulli(x, x_new, reduction='sum', dim=-1)\n",
        "\n",
        "    return log_prob\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEvP6chRJQ_v"
      },
      "source": [
        "http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2GSk5YuIR3M"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "#test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKPrUR6ypP52"
      },
      "source": [
        "likelihood_type = 'categorical'\n",
        "\n",
        "if likelihood_type == 'categorical':\n",
        "    num_vals = 256\n",
        "elif likelihood_type == 'bernoulli':\n",
        "    num_vals = 1\n",
        "\n",
        "prior_distribution = 'standard normal'"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FwKPPMwHm6x"
      },
      "source": [
        "D = 28*28\n",
        "H = 98\n",
        "L = 16\n",
        "\n",
        "\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 100"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bj4iLyRU1UA"
      },
      "source": [
        "model = VAE(D, H, L, likelihood_type, num_vals, prior_distribution)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYaRbY3TGhrx"
      },
      "source": [
        "train_loss_avgs = []\n",
        "best_loss = 1000.\n",
        "\n",
        "model.train()\n",
        "print(\"Training...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  num_batches = 0\n",
        "  train_loss_avgs.append(0)\n",
        "\n",
        "  for batch_idx, (data, labels) in enumerate(train_dataloader):\n",
        "\n",
        "    data = data.to(device)\n",
        "   \n",
        "    loss = model.forward(data)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss_avgs[-1] += loss.item()\n",
        "    num_batches +=1\n",
        "\n",
        "  train_loss_avgs[-1] /= num_batches\n",
        "  print('Epoch [%d / %d] average training loss: %f' % (epoch+1, num_epochs, train_loss_avgs[-1]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l67D9Mb-bdyt"
      },
      "source": [
        "torch.save(model.state_dict(), \"./Trained Models/VAE_First\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnyPgvAJUoKa",
        "outputId": "03afc31b-b368-404c-dc92-dbb857473b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plt.ion()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(train_loss_avgs)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAsQs2elU_GI",
        "outputId": "561fb1d9-f251-432e-bf39-684d5a1fdb9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "filename =  \"/VAE_First\"\n",
        "\n",
        "import urllib\n",
        "if not os.path.isdir('./Trained Models'):\n",
        "    os.makedirs('./Trained Models')\n",
        "print('downloading ...')\n",
        "\n",
        "model.load_state_dict(torch.load('./Trained Models'+filename))\n",
        "print('done')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading ...\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBG3Ga0SWAzq"
      },
      "source": [
        "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFa1Z2UlV2Om",
        "outputId": "02a9948f-2ef4-4b3e-9709-8bfdc6456aed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "test_loss_avgs, num_batches = 0, 0\n",
        "\n",
        "for batch_idx, (data, labels) in enumerate(test_dataloader):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        data = data.to(device)\n",
        "\n",
        "        # reconstruction error\n",
        "        loss = model.forward(data)\n",
        "\n",
        "        test_loss_avgs += loss.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "test_loss_avgs /= num_batches\n",
        "print('average loss: %f' % (test_loss_avgs))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average loss: 32.670988\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}