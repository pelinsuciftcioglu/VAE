{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/pelinsuciftcioglu/VAE/blob/main/VAE.ipynb",
      "authorship_tag": "ABX9TyP5cGpD8Ng7vNiKV8kMQTyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pelinsuciftcioglu/VAE/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGnGq9I4RJZi"
      },
      "source": [
        "# **Variational Auto-Encoder (VAE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II9CkyMLhgIj"
      },
      "source": [
        "VAE implementation inspired by:\n",
        "- [Tomczak, J. M. (2021). Introduction to Deep Generative Modeling.](https://https://github.com/jmtomczak/intro_dgm)\n",
        "- [CreativeAI: Deep Learning for Graphics Tutorial Code\n",
        "](https://github.com/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr7xJ0hJwUZ5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "use_gpu = True"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7rMFdHqXJYZ"
      },
      "source": [
        "PI = torch.from_numpy(np.asarray(np.pi))\n",
        "EPS = 1.e-5\n",
        "\n",
        "# DISTRBUTION FOR THE DATA (INPUT)\n",
        "\n",
        "def log_categorical(x, x_new, num_classes, reduction=None, dim=None):\n",
        "    x_one_hot = F.one_hot(x.long(), num_classes)\n",
        "    log_p = x_one_hot * torch.log(torch.clamp(x_new, EPS, 1. - EPS))\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "def log_bernoulli(x, x_new, reduction=None, dim=None):\n",
        "    x_new = torch.clamp(x_new, EPS, 1. - EPS)\n",
        "    log_p = x * torch.log(x_new) + (1. - x) * torch.log(1. - x_new)\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "# DISTRIBUTION FOR THE VARIATIONAL INFERENCE\n",
        "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
        "    D = x.shape[1]\n",
        "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2.\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p\n",
        "\n",
        "\n",
        "# PRIOR DISTRIBUTIONS for p(z)\n",
        "\n",
        "def log_standard_normal(x, reduction=None, dim=None):\n",
        "    D = x.shape[1]\n",
        "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * x**2.\n",
        "    if reduction == 'avg':\n",
        "        return torch.mean(log_p, dim)\n",
        "    elif reduction == 'sum':\n",
        "        return torch.sum(log_p, dim)\n",
        "    else:\n",
        "        return log_p"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMVbn06LxAM4"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, D, H, L):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.encoder_net = nn.Sequential(nn.Linear(D, H), nn.LeakyReLU(), nn.Linear(H, H), nn.LeakyReLU(), nn.Linear(H, 2*L))\n",
        "\n",
        "    def encode(self, x):\n",
        "      mu, log_var = self.forward(x)\n",
        "      return mu, log_var\n",
        "\n",
        "    def forward(self, x):\n",
        "      h = self.encoder_net(x)\n",
        "      mu, log_var =  torch.chunk(h, 2, dim=1)\n",
        "\n",
        "      return mu, log_var\n",
        "\n",
        "    def sample(self, mu, log_var):\n",
        "      std = torch.exp(0.5 * log_var)\n",
        "      # Sample epsilon ~ N(0,I)\n",
        "      eps = torch.randn_like(std)\n",
        "      # Reparameterization trick\n",
        "      z = mu + eps * std\n",
        "\n",
        "      return z\n",
        "\n",
        "    def log_prob(self, mu, log_var, z):\n",
        "      return log_normal_diag(z, mu, log_var)\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT7wpoop1PJJ"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, D, H, L, distribution, num_vals):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.D = D\n",
        "        self.distribution = distribution\n",
        "        self.num_vals = num_vals\n",
        "\n",
        "        self.decoder_net = nn.Sequential(nn.Linear(L, H), nn.LeakyReLU(), nn.Linear(H, H), nn.LeakyReLU(), nn.Linear(H, D * num_vals))\n",
        "\n",
        "    def decode(self, z):\n",
        "      x_new = self.forward(z)\n",
        "\n",
        "      return x_new\n",
        "\n",
        "    def forward(self, z):\n",
        "      x_new = self.decoder_net(z)\n",
        "      \n",
        "      if self.distribution == 'categorical':\n",
        "        b = x_new.shape[0]\n",
        "        d = self.D\n",
        "        x_new = x_new.reshape(b, d, self.num_vals)\n",
        "        return torch.softmax(x_new, 2)\n",
        "      \n",
        "      elif self.distribution == 'bernoulli':\n",
        "        return torch.sigmoid(x_new)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMV2Vv6rYVOM"
      },
      "source": [
        "class Prior(nn.Module):\n",
        "    def __init__(self, L, prior_distribution):\n",
        "        super(Prior, self).__init__()\n",
        "        self.L = L\n",
        "        self.distribution = prior_distribution\n",
        "\n",
        "    # def sample(self, batch_size):\n",
        "    #     z = torch.randn((batch_size, self.L))\n",
        "    #     return z\n",
        "\n",
        "    def log_prob(self, z):\n",
        "      if (self.distribution == 'standard normal'):\n",
        "        return log_standard_normal(z)\n",
        "\n",
        "      # elif self.distribution == ''\n",
        "        # return log____(z)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzfVgQYtP-Lg"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self, D, H, L, distribution, num_vals, prior_distribution): # Initializations should be added!!!!\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = Encoder(D, H, L)\n",
        "        self.decoder = Decoder(D, H, L, distribution, num_vals)\n",
        "        self.prior = Prior(L, prior_distribution)\n",
        "\n",
        "\n",
        "        self.num_vals = num_vals\n",
        "        self.distribution = distribution\n",
        "  \n",
        "  def forward(self, x, reduction='avg'):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        #print(x.size())\n",
        "        #print(x[0])\n",
        "        mu, log_var = self.encoder.encode(x)\n",
        "        z = self.encoder.sample(mu, log_var)\n",
        "\n",
        "        ELBO = self.loss(x, z, mu, log_var, reduction)\n",
        "\n",
        "        return ELBO\n",
        "  \n",
        "  def loss(self, x, z, mu, log_var, reduction='avg'):\n",
        "    # Reconstruction Error\n",
        "    RE = self.log_prob(x, z)\n",
        "\n",
        "    # KL-Divergence\n",
        "    KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu, log_var, z)).sum(-1)\n",
        "\n",
        "    if reduction == 'sum':\n",
        "      return -(RE + KL).sum()\n",
        "    else:\n",
        "      return -(RE + KL).mean()\n",
        "\n",
        "\n",
        "  def log_prob(self, x, z):\n",
        "    x_new = self.decoder.decode(z)\n",
        "\n",
        "    if self.distribution == 'categorical':\n",
        "      log_prob = log_categorical(x, x_new, self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
        "            \n",
        "    elif self.distribution == 'bernoulli':\n",
        "      log_prob = log_bernoulli(x, x_new, reduction='sum', dim=-1)\n",
        "\n",
        "    return log_prob\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEvP6chRJQ_v"
      },
      "source": [
        "http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6iSaLkBfA-7"
      },
      "source": [
        "import math\n",
        "import numbers\n",
        "import warnings\n",
        "from enum import Enum\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from typing import List, Tuple, Any, Optional\n",
        "\n",
        "try:\n",
        "    import accimage\n",
        "except ImportError:\n",
        "    accimage = None\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si5Apcn1dhDW"
      },
      "source": [
        "class ToTensor:\n",
        "    def __call__(self, pic):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
        "        Returns:\n",
        "            Tensor: Converted image.\n",
        "        \"\"\"\n",
        "        return to_tensor(pic)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '()'"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zen4WLidinj"
      },
      "source": [
        "def to_tensor(pic):\n",
        "    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
        "    This function does not support torchscript.\n",
        "    See :class:`~torchvision.transforms.ToTensor` for more details.\n",
        "    Args:\n",
        "        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
        "    Returns:\n",
        "        Tensor: Converted image.\n",
        "    \"\"\"\n",
        "    default_float_dtype = torch.get_default_dtype()\n",
        "\n",
        "    if isinstance(pic, np.ndarray):\n",
        "        # handle numpy array\n",
        "        if pic.ndim == 2:\n",
        "            pic = pic[:, :, None]\n",
        "\n",
        "        img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
        "        # backward compatibility\n",
        "        if isinstance(img, torch.ByteTensor):\n",
        "            return img.to(dtype=default_float_dtype).div(255)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "    if accimage is not None and isinstance(pic, accimage.Image):\n",
        "        nppic = np.zeros([pic.channels, pic.height, pic.width], dtype=np.float32)\n",
        "        pic.copyto(nppic)\n",
        "        return torch.from_numpy(nppic).to(dtype=default_float_dtype)\n",
        "\n",
        "    # handle PIL Image\n",
        "    mode_to_nptype = {'I': np.int32, 'I;16': np.int16, 'F': np.float32}\n",
        "    img = torch.from_numpy(\n",
        "        np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True)\n",
        "    )\n",
        "\n",
        "    if pic.mode == '1':\n",
        "        img = 255 * img\n",
        "    img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))\n",
        "    # put it from HWC to CHW format\n",
        "    img = img.permute((2, 0, 1)).contiguous()\n",
        "    if isinstance(img, torch.ByteTensor):\n",
        "        return img.to(dtype=default_float_dtype)\n",
        "    else:\n",
        "        return img"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_pbbTO8wfUE"
      },
      "source": [
        "# class ToTensor:\n",
        "#   def __call__(self, pic):\n",
        "#     default_float_dtype = torch.get_default_dtype()\n",
        "#     mode_to_nptype = {'I': np.int32, 'I;16': np.int16, 'F': np.float32}\n",
        "#     pic = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))\n",
        "#     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))\n",
        "#     # put it from HWC to CHW format\n",
        "#     img = img.permute((2, 0, 1)).contiguous()\n",
        "#     return img.to(dtype=default_float_dtype)\n",
        "\n",
        "#   def __repr__(self):\n",
        "#     return self.__class__.__name__ + '()'\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2GSk5YuIR3M"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "img_transform = transforms.Compose([ToTensor()])\n",
        "\n",
        "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "\n",
        "#test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTPpAd7GIPQp"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# import tensorflow_datasets as tfds\n",
        "\n",
        "# (ds_train, ds_test), ds_info = tfds.load(\n",
        "#     'mnist',\n",
        "#     split=['train', 'test'],\n",
        "#     shuffle_files=True,\n",
        "#     as_supervised=True,\n",
        "#     with_info=True,\n",
        "# )\n",
        "\n",
        "# def castToFloat(image, label):\n",
        "#   \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "#   return tf.cast(image, tf.float32), label\n",
        "\n",
        "# ds_train = ds_train.map(castToFloat, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "# ds_train = ds_train.batch(128)\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKPrUR6ypP52"
      },
      "source": [
        "likelihood_type = 'categorical'\n",
        "\n",
        "if likelihood_type == 'categorical':\n",
        "    num_vals = 256\n",
        "elif likelihood_type == 'bernoulli':\n",
        "    num_vals = 1\n",
        "\n",
        "prior_distribution = 'standard normal'"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FwKPPMwHm6x"
      },
      "source": [
        "D = 28*28\n",
        "H = 98\n",
        "L = 16\n",
        "\n",
        "\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 100"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bj4iLyRU1UA"
      },
      "source": [
        "model = VAE(D, H, L, likelihood_type, num_vals, prior_distribution)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lxs797lIN0u"
      },
      "source": [
        "      # print(data[0])\n",
        "\n",
        "      # break\n",
        "\n",
        "      #data = data.requires_grad_(True)   \n",
        "      #print(data.size())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYaRbY3TGhrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ab3c64-7711-47ef-8daa-32c2486184a4"
      },
      "source": [
        "from torch import autograd\n",
        "\n",
        "\n",
        "train_loss_avgs = []\n",
        "best_loss = 1000.\n",
        "\n",
        "model.train()\n",
        "print(\"Training...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss_avgs.append(0)\n",
        "\n",
        "  for batch_idx, (data, labels) in enumerate(train_dataloader, 1):\n",
        "\n",
        "\n",
        "    with autograd.detect_anomaly():\n",
        "\n",
        "      data = data.to(device)\n",
        "\n",
        "     \n",
        "      \n",
        "      loss = model.forward(data)    \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward(retain_graph=True)    \n",
        "      optimizer.step()    \n",
        "      train_loss_avgs[-1] += loss.item()\n",
        "      num_batches = batch_idx\n",
        "\n",
        "  train_loss_avgs[-1] /= num_batches\n",
        "  print('Epoch [%d / %d] average training loss: %f' % (epoch+1, num_epochs, train_loss_avgs[-1]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1 / 100] average training loss: 182816.797745\n",
            "Epoch [2 / 100] average training loss: 941.475655\n",
            "Epoch [3 / 100] average training loss: 901.875227\n",
            "Epoch [4 / 100] average training loss: 880.934248\n",
            "Epoch [5 / 100] average training loss: 865.473629\n",
            "Epoch [6 / 100] average training loss: 852.865510\n",
            "Epoch [7 / 100] average training loss: 842.046179\n",
            "Epoch [8 / 100] average training loss: 832.676572\n",
            "Epoch [9 / 100] average training loss: 824.705095\n",
            "Epoch [10 / 100] average training loss: 817.815327\n",
            "Epoch [11 / 100] average training loss: 811.267198\n",
            "Epoch [12 / 100] average training loss: 804.943420\n",
            "Epoch [13 / 100] average training loss: 798.308011\n",
            "Epoch [14 / 100] average training loss: 792.083878\n",
            "Epoch [15 / 100] average training loss: 786.066778\n",
            "Epoch [16 / 100] average training loss: 779.927880\n",
            "Epoch [17 / 100] average training loss: 773.453908\n",
            "Epoch [18 / 100] average training loss: 767.493638\n",
            "Epoch [19 / 100] average training loss: 761.703338\n",
            "Epoch [20 / 100] average training loss: 755.276115\n",
            "Epoch [21 / 100] average training loss: 749.704600\n",
            "Epoch [22 / 100] average training loss: 744.808928\n",
            "Epoch [23 / 100] average training loss: 740.758813\n",
            "Epoch [24 / 100] average training loss: 736.440649\n",
            "Epoch [25 / 100] average training loss: 732.436840\n",
            "Epoch [26 / 100] average training loss: 728.801867\n",
            "Epoch [27 / 100] average training loss: 725.620020\n",
            "Epoch [28 / 100] average training loss: 721.723083\n",
            "Epoch [29 / 100] average training loss: 718.719755\n",
            "Epoch [30 / 100] average training loss: 715.445683\n",
            "Epoch [31 / 100] average training loss: 712.783519\n",
            "Epoch [32 / 100] average training loss: 709.933048\n",
            "Epoch [33 / 100] average training loss: 707.607478\n",
            "Epoch [34 / 100] average training loss: 705.486546\n",
            "Epoch [35 / 100] average training loss: 703.127697\n",
            "Epoch [36 / 100] average training loss: 700.804835\n",
            "Epoch [37 / 100] average training loss: 698.664658\n",
            "Epoch [38 / 100] average training loss: 697.275372\n",
            "Epoch [39 / 100] average training loss: 695.170181\n",
            "Epoch [40 / 100] average training loss: 693.646119\n",
            "Epoch [41 / 100] average training loss: 691.908727\n",
            "Epoch [42 / 100] average training loss: 690.460009\n",
            "Epoch [43 / 100] average training loss: 688.905401\n",
            "Epoch [44 / 100] average training loss: 687.833419\n",
            "Epoch [45 / 100] average training loss: 686.319943\n",
            "Epoch [46 / 100] average training loss: 684.712952\n",
            "Epoch [47 / 100] average training loss: 683.829861\n",
            "Epoch [48 / 100] average training loss: 682.558100\n",
            "Epoch [49 / 100] average training loss: 681.556512\n",
            "Epoch [50 / 100] average training loss: 680.554206\n",
            "Epoch [51 / 100] average training loss: 679.437156\n",
            "Epoch [52 / 100] average training loss: 678.768226\n",
            "Epoch [53 / 100] average training loss: 677.704002\n",
            "Epoch [54 / 100] average training loss: 676.727767\n",
            "Epoch [55 / 100] average training loss: 675.991177\n",
            "Epoch [56 / 100] average training loss: 675.034481\n",
            "Epoch [57 / 100] average training loss: 674.361466\n",
            "Epoch [58 / 100] average training loss: 673.273868\n",
            "Epoch [59 / 100] average training loss: 672.943200\n",
            "Epoch [60 / 100] average training loss: 671.780425\n",
            "Epoch [61 / 100] average training loss: 671.373836\n",
            "Epoch [62 / 100] average training loss: 670.334337\n",
            "Epoch [63 / 100] average training loss: 669.581749\n",
            "Epoch [64 / 100] average training loss: 668.774956\n",
            "Epoch [65 / 100] average training loss: 668.469225\n",
            "Epoch [66 / 100] average training loss: 667.677998\n",
            "Epoch [67 / 100] average training loss: 666.983215\n",
            "Epoch [68 / 100] average training loss: 666.069647\n",
            "Epoch [69 / 100] average training loss: 665.137574\n",
            "Epoch [70 / 100] average training loss: 665.170253\n",
            "Epoch [71 / 100] average training loss: 663.951273\n",
            "Epoch [72 / 100] average training loss: 663.616562\n",
            "Epoch [73 / 100] average training loss: 663.208772\n",
            "Epoch [74 / 100] average training loss: 662.305646\n",
            "Epoch [75 / 100] average training loss: 661.761443\n",
            "Epoch [76 / 100] average training loss: 660.970306\n",
            "Epoch [77 / 100] average training loss: 660.663721\n",
            "Epoch [78 / 100] average training loss: 659.989006\n",
            "Epoch [79 / 100] average training loss: 659.378847\n",
            "Epoch [80 / 100] average training loss: 658.870897\n",
            "Epoch [81 / 100] average training loss: 658.882407\n",
            "Epoch [82 / 100] average training loss: 657.865766\n",
            "Epoch [83 / 100] average training loss: 657.839121\n",
            "Epoch [84 / 100] average training loss: 657.205552\n",
            "Epoch [85 / 100] average training loss: 656.343230\n",
            "Epoch [86 / 100] average training loss: 656.342401\n",
            "Epoch [87 / 100] average training loss: 655.374152\n",
            "Epoch [88 / 100] average training loss: 655.214272\n",
            "Epoch [89 / 100] average training loss: 654.654353\n",
            "Epoch [90 / 100] average training loss: 654.382594\n",
            "Epoch [91 / 100] average training loss: 654.045465\n",
            "Epoch [92 / 100] average training loss: 653.353255\n",
            "Epoch [93 / 100] average training loss: 653.334250\n",
            "Epoch [94 / 100] average training loss: 652.603708\n",
            "Epoch [95 / 100] average training loss: 652.620819\n",
            "Epoch [96 / 100] average training loss: 651.792387\n",
            "Epoch [97 / 100] average training loss: 651.262648\n",
            "Epoch [98 / 100] average training loss: 651.275593\n",
            "Epoch [99 / 100] average training loss: 650.993099\n",
            "Epoch [100 / 100] average training loss: 650.494595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnyPgvAJUoKa",
        "outputId": "105e9914-e8de-4429-9e0d-b9eb52140937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "plt.ion()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(train_loss_avgs[1:])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l67D9Mb-bdyt"
      },
      "source": [
        "\n",
        "import urllib\n",
        "if not os.path.isdir('./Trained Models'):\n",
        "    os.makedirs('./Trained Models')\n",
        "\n",
        "torch.save(model.state_dict(), \"./Trained Models/VAE_First\")"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAsQs2elU_GI",
        "outputId": "c432c79f-d349-4ff9-b3af-8c5b20367678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "filename =  \"/VAE_First\"\n",
        "\n",
        "print('downloading ...')\n",
        "\n",
        "model.load_state_dict(torch.load('./Trained Models'+filename))\n",
        "print('done')\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading ...\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBG3Ga0SWAzq"
      },
      "source": [
        "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFa1Z2UlV2Om",
        "outputId": "c0ee19f5-060d-4aca-dcd7-8c25ffbfadc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "test_loss_avgs, num_batches = 0, 0\n",
        "\n",
        "for batch_idx, (data, labels) in enumerate(test_dataloader):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        data = data.to(device)\n",
        "\n",
        "        # reconstruction error\n",
        "        loss = model.forward(data)\n",
        "\n",
        "        test_loss_avgs += loss.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "test_loss_avgs /= num_batches\n",
        "print('average loss: %f' % (test_loss_avgs))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average loss: 798.117806\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}